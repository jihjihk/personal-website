{
	"week11": 
	{
		"week" : "week11",
		"title" : "Ownership in the Digital Space",
		"subtitle" : "Drawing Different Boundaries Around Property",
		"date" : "November 20, 2017",
		"text" :"<p>The definition of ownership has changed significantly as the digital space has enlarged over the past few decades because the internet has changed a property’s protection mechanisms--namely the market, norms, and nature--that Lessig pointed out in his book. These mechanisms differ significantly for a physical, valuable good versus a digital intellectual property like e-books and movies. The nature mechanism of intellectual property in the cyberspace refers to its physical non-existence that “conspires with thieves” and allows not just stealing but making multiple copies of the property. The market protection mechanism for physical goods makes more marketable and high-demand goods to be more prone to stealing. This principle applies directly to piracy of digital property as well, as exemplified by the large seeder number for popular files that makes torrenting much faster and easier.</p> <p>Yet the expected norm, as a means to protect piracy, is still unclear. The relative infancy of ethics and regulations around digital commodity has not settled on a universally agreed upon values around piracy, despite its universal accessibility. While ethical norms are often culture specific, thus not always universally accepted, they are also confined to the physical space in which the culture largely draws a boundary around it. Yet the fundamental purpose of the World Wide Web to be accessible to any and all strikes contrast with the lack of governmental or cultural norm that all internet users recognize.</p> <p>Similarly, the older definition of copyright laws depended on the “high costs of control,” which guaranteed some liberty and anonymity. Yet today’s significantly lowered costs of control also threatens the degree of liberty from regulation. Lessig goes on to discuss the possibility of architecting a system in which software can guarantee restricted but reasonable access to intellectual property. Whether any government can play the same role in determining the new norm of creation and consumption in the digital space, which is not bound by the same national borders it governs, especially when political agendas underlie reinforcement of property protection, is a question we must answer as a collective of distributed shapers of the internet.</p>"
	},
	"week10": 
	{
		"week" : "week10",
		"title" : "Labor",
		"subtitle" : "Marketplace Economy and Information Asymmetry",
		"date" : "November 13, 2017",
		"text" :"<p>The past year's scandals surrounding Uber has shown us what a misdirected platform business is capable of in discriminating against workers. From a series of workplace sexual harassment to surging commission on drivers, Uber demonstrated that software systems, through information asymmetry, are more than capable of affecting various segments of the labor market in unexpected and powerful ways. This phenomenon is not unique to Uber; as pointed out in <a class='intext' href='https://thenewinquiry.com/the-ladies-vanish/'> the Ladies Vanish</a> article points out, similar attempts to mask belaboring and tedious works of humans behind the sexy tech of “on-demand magic” are almost universal across the tech industry. </p> <p> We previously talked about how today's technology is becoming increasingly abstract, thus becoming more accessible but less understandable. While the more obvious abstraction happens on the code level, such as API, libraries, and GUI, the more consequential abstraction happens when we separate and hide human labor from the user-friendly front end of software. <a class='intext' href='http://www.imdb.com/title/tt4846340/'>The Hidden Figures movie</a> was based on the story of three female engineers at NASA in 1961 and their achievements that were mostly hidden due to gender and race discrimination. More than a half century later, however, the concealment of undesirable and unpowerful labor force is still very much existent, if not more systematic in the “marketplace” economy that on-demand apps have created. </p> <p>Technology and automation have helped workers become more productive by completing tedious and repetitive tasks and has also created new jobs that are more relevant to fast changing market demand. To dismiss technological progress as the main culprit of unemployment therefore seems naive. Yet as the <a class='intext' href='https://www.technologyreview.com/s/515926/how-technology-is-destroying-jobs/'>How Technology Is Destroying Jobs</a> article states, “It's one of the dirty secrets of economics: technology progress does grow the economy and create wealth, but there is no economic law that says everyone will benefit.” The increasing abstraction of technology has created an information--and power--asymmetry at an unprecedented scale. When centralized platforms and marketplaces take control of this power while denying all legal responsibility for labor and safety of their non-employee contractors, the supply side becomes insignificant and incapable of intervening against unfair treatment.</p> <p>So how do users intervene? Do we only hope for philanthropic CEOs and software engineers to reject profit maximization and to operate as social enterprises? If there can be alternative services we can use that provide not only competitive monetary and time but also social benefit, perhaps there can be an additional motivation for these platform businesses to consider the good for all stakeholders in a system. Juno, for example, is a ride-sharing company that launched in New York in 2016 and takes a 'smaller cut off every ride: Just 10% compared to Uber's 20% to 25%', as part of a strategy to attract and retain happier drivers. By only accepting already trained Uber or Lyft drivers with high ratings and advertising mainly through word-of-mouth, the business is able to cut training and advertising costs that are reallocated directly to drivers' commission. By sometime in May or June this year, almost every Lyft driver I met in New York had Juno app on display in their cars. Every driver was excited to share how much more empowering Juno is to drivers than other ride hailing services. I wondered if a right intention and vision of a company is enough to prevent the abuse of information asymmetry. AT the same time, the distributed networks perhaps can one day remove this trust from the equation to create a fairer labor system.</p>"
	},
	"week9": 
	{
		"week" : "week9",
		"title" : "The Weak AI",
		"subtitle" : "Not the strong AI we fear",
		"date" : "November 5, 2017",
		"text" :"<p>The term “Artificial Intelligence” is used more frequently now, often with an underlying tone of impending threat to replace human intelligence. The recent achievements in artificial intelligence research, especially in parallel with those infrastructural level progresses in computing power, certainly promise a larger role that machines will play in our economy. To directly make an assumption that this replacement in jobs equals replacement in complete intelligence, however, may yet be unfounded, a large reason for it being language. </p> <p>First of all, there is a clear distinction between artificial general intelligence, or strong AI, and narrow AI. Most commercialized AI we have now are “narrow” in that they are good at one specific task, such as playing Go, but the same AI cannot easily transfer its specific intelligence to other simple tasks. This is due to the “illusion” of intelligence as pointed out by the <a class='intext' href='https://www.technologyreview.com/s/602094/ais-language-problem/'>AI's Language Problem</a> article refers to the lack of common sense, let alone emotional and social intelligence, that today's AI lacks but humans often overlook. The problem lies in the myopic methods humans use to quantify intelligence. Deep learning, as demonstrated in AlphaGo's win against Sedol Lee, has enabled machines to capture a new dimension of instinctive knowledge of humans but is still limited to the medium of how information is represented. For example, image and video recognition, despite its much, much larger vector space than words, has approached very impressive accuracy. Yet deciphering language is much harder than identifying the object in an image because language is captured in three very different layers of syntactic, semantic, and pragmatic meanings, the latter two of which are very hard to represent in vectors.</p> <p>Another problem is the question of whether AI can ever achieve creative intelligence. The fundamental necessity of any machine learning being training data, every algorithm learns by training on data, thus dependent on the amount of data for accuracy. It can attempt to generate, instead of simply comprehend, a concept but hasn't succeeded much as demonstrated in the <a class='intext' href='https://www.theatlantic.com/technology/archive/2017/05/when-a-robot-names-a-new-color-of-paint/527421/'>color naming example.</a> Human creativity is an interesting mix of learning from examples, randomness, and some creative consciousness. To humans, the consciousness almost comes naturally, even with very little “training data” that we encounter. Capturing this creative consciousness may not be as simple as learning from the left-right brain dichotomy mentioned in Weizenbaum's writing.</p> <p>Beyond this technical feasibility of <em>how</em>, the philosophical question of <em>why</em> still remains. Many of us have come to equate jobs with purpose in life, thus fearing the AI's increasing involvement in strictly economic activities as a threat to our existence. As Weizenbaum pointed out, beings/organisms are shaped by the problems they face and that sense machines will never be humans. When we try to emulate a specific human knowledge in machines, it is still a tool that humans use. To give more weight to a machine intelligence than as a tool and fear it then appears unintelligible, on human's side.</p>"
	},
	"week8": 
	{
		"week" : "week8",
		"title" : "Social Networks",
		"subtitle" : "Once upon a time in 2012",
		"date" : "October 30, 2017",
		"text" :"<p>A lot has changed for Facebook since 2012, when the article <a class='intext' href=’https://www.technologyreview.com/s/428150/what-facebook-knows/’>What Facebook Knows</a> was written; over the past 5 years, Facebook not only doubled its monthly active user number from 1 billion to 2 billion, but also grew its revenue from 5 billion USD to 27.5 billion USD. Just in the span of 5 years, the entire advertising revenue concentrated to either Facebook or Google, the two companies that reap almost <a class='intext' href=’http://fortune.com/2017/04/26/google-facebook-digital-ads/’>100%</a> of today’s digital ad revenue growth. This monopolistic growth could only come with the huge amount and specificity of data that Facebook has accumulated over the years, so it's hard to imagine that then the entire data science team at Facebook was only 12 people.</p> <p>It’s not just the user number and ad revenue that changed for Facebook; the more significant change that Facebook precipitated is perhaps our social behavior and habits around social media. In the article, Eytan Bakshy is quoted as saying how teams at Facebook only began to predict the “echo chamber” it puts users in and the polarized voter reactions to various recent political events very well reflect this echo chamber after 5 years of its initial conception.</p> <p>The social experiments that engineering teams were able conduct fast and at massive scale were also interestingly explained by “the primary goal of his team to support the wellbeing of the people who provide Facebook with their data, using it to make the service smarter.” This reminded me of the 12 Leverage Points by Donella Meadows. In her writing, she makes a clear distinction between goal, paradigm, and making profit. By her definition, the goal of every system is to grow in size and control over the population, paradigm is an ideology that the system was created out of, and making profit is a mere condition to keep the system running. I think this statement that Marlow makes about company’s primary goal is exactly what makes Facebook users users not customers; users are shown the abstracted, ambiguous layer of some paradigm but are hidden from its true goal to know more and control more.</p>"},
	"week7": 
	{
		"week" : "week7",
		"title" : "Software Leverage Points",
		"subtitle" : "Places to intervene in a software system",
		"date" : "October 27, 2017",
		"text" :"<p>Software systems of virtual worlds are emerging to match the traditional systems in their magnitude and extent of influence. Using Twelve Leverage Points proposed by Donella H. Meadows, software creators and system organizers can identify leverage points--where small shift in one thing can produce big changes in everything--in software systems as well. The prevalence of open-source governance and fast-changing nature of software may yield different leverage points than those in economic growth systems that are more closed and slow to adapt. There were still very interesting parallels that could inspire more software creators and consumers to clearly recognize where and how they could intervene in the increasingly ambiguous and scary AI and automation world of black box algorithms. </p><p> While all twelve leverage points are relevant, I wanted to look closer into the most effective few. The fourth that Meadows put forward is \"the power to add, change, evolve, or self-organize system structure.\" She highlights the importance of adaptability and open-mindedness of any system to survive in highly volatile environment. To aid the development of such resilience then requires \"clevel rules for self-organization.\" I thought this relates well to the internet protocols and <a class='intext' href='http://wiki.civiccommons.org/Open_Source_Development_Guidelines/'>Open Source Development Guidelines</a> that are ultimately these \"rules for self-organization\" that are essential for functioning self-organization that is very effective in intervening in a system. The fast evolution cycle of most open source programs through systematic version control and easy public contribution helps these systems avoid \"insistence on a single culture [that] shuts down learning.\" </p><p> The goals of systems and the mindset out of which the system arose also reflect an interesting dichotomy between initial purpose and gradual evolution of many software applications, especially within for-profit and private companies. Meadows makes a clear distinction between profit-making and goal of a system; making profit is necessary condition to stay in the game, whereas the goal is \"to grow, to increase market share, to bring the world more and more under the control of the corporation so that its operations become ever more shielded from uncertainty.\" Proliferating public relations effort of most companies has allowed users of software systems to directly believe in the initial paradigm of the company’s creation to be the goal, like Facebook and <a class='intext' href='https://www.facebook.com/zuck/videos/10103817960742861/'>its recent mission statement</a> to ‘bring the world closer together.’ The incredible user base size of Facebook, now in billions, is one of many indicators of Facebook’s success in this most fundamental goal: to grow, both in numbers and in control. For a growing portion of its user base that feels less control over their software use, perhaps the most crucial first step is to correctly identify and discern the software company’s most fundamental goal, then to leverage this knowledge for an effective leverage point that will produce big changes.</p>"
	},
	"week6": 
	{
		"week" : "week6",
		"title" : "Government Control",
		"subtitle" : "An asymmetrically distributed system",
		"date" : "October 9, 2017",
		"text" :"<p>As the boundary between technical and social decisions blurs, it is increasingly important to understand the potential impact a software can have within a community that utilizes it. This comprehension, however, remains a privilege and responsibility restricted to few software engineers and designers as mass adoption of a technology can only happen after enough layers of obscurity and abstraction for wide public to intuitively adopt and utilize. In a sense user experience is the middle layer that masks transistors and translates binary code to human-readable buttons. This ironic cycle of technology going through abstraction for thus consequences to the public will probably remain a dilemma without a solution. </p><p> Galloway, in his book introduction in \"Protocol: Control After Decentralization\", described the internet as an organized placed of information thanks to the protocol that reconciles its two machinic technology: the non-hiearchicial, peer-to-peer relationship of TCP/IP and the rigidly defined hierarchies of DNS. These protocols function as \"recommendations and rules that outline specific technical standards\" and therefore organize the internet and the society into distributed systems. While beautiful in its analogies and abstraction of the internet, I found it contradictory to the commercialized reality of today's internet businesses that thrive on centralized, mass collection of data. One could argue that this only reflects rigid, hierarchical one of the two sides machinic techonlogies, as many individuals have simultaneously gained access to the distributed network of information that these platforms provide. The balance of these two sides of social media, however, is questionable. </p><p> The clear information and power asymmetry demonstrated by today's Facebooks and Twitters reflect that neither the internet nor its users are parts of truly distributed networks that TCP/IP may embody on a protocol level. In Tufekci's paper on \"Engineering the Public\" the author mentions how proliferation of data generated by the public has been used at the public by politicians and companies that mask this influence in \"black box algorithms.\" The author refers to information asymmetry that with centralized data and modeling, campaigns create an illusion that candidates can now understand and address the public sphere's common needs better, when in reality they only improved the speed and cost efficiency of individual-targetted advertisement. Will a shift to a more distributed of data ownership and influence come in the near future, and if so, how will it change the public sphere as this generation's internet companies already have?</p>"
	},
	"week5": 
	{
		"week" : "week5",
		"title" : "Popular Organization",
		"subtitle" : "How social media elected and impeached South Korean president",
		"date" : "October 5, 2017",
		"text" :"<p>Social Media serves as both important means of political activism and censorship of free communication, especially in the context of public dissidents against the state on social media. This dichotomy slowly emerged from the initial rise of the world wide web that promised a free cyberspace that turned into a more central, commercial and surveiled space. </p><p> The recent Korean candlelight protest that led to the first ever presidential impeachment embodies this dichotomy of social media well. What started as a university protest against a bribery and nepotism in the summer of 2016 was able to trigger a nationwide, 4 months long protest attended by more than 16 million people to bring down a corrupt country's president, her friend, and Samsung's president and social media was critical in many ways throughout the process. For example, it helped spread the news about the scandal amongst a generation of citizens that no longer watched TV and the public broadcasting stations that were famously state-controlled. Many citizens in their 20s and 30s relied on a smaller, private news channel named JTBC that gained a lot of trust for frequently speaking out against the government in the past despite retaliation. JTBC was also active in emphasizing its humanity and empathy in their short, shareable videos of daily news, live broadcast of trials, and interactive Q&A on social media channels to engage and inform younger generations of voters, which I believe played a huge role in the active participation of the youth in weekly candlelight protests. </p><p> Another role social media played was organizing the weekly protests and popularizing the act of protest itself. Protesting weekly, even during the coldest weekends, was made accessible and communal by almost ubiquitous footages of friends, celebrities, politicians and even nationally popular athletes holding candles in public squares on Twitter and Facebook. The total toll of protesters exceeded 20% of the country's population without any casualty or violence during main protests, because protests were portrayed as social and peaceful gatherings--not violent uproar--that united both the public and the police against the common enemy of corrupt leaders in both the government and the Samsung empire. </p><p> It is also interesting to note that social media, despite its active role in impeaching Park, was what elected her in the first place. The change of governments this May instantly led to trial of a number of ex-intelligence members and their prosecution for public opinion manipulation during 2012 election using social media. They admitted to posting favorable comments and re-tweets for the impeached Park when she was a running candidate in 2012 and shaming her contender Moon in numerous social media posts. While the allegations for NIS' public opinion manipulation have been open for years, the previous government's strong grasp of all executive and legislative branch didn't allow for proper investigation of the matter. </p><p> Social media used by the state allowed Park Geun Hye to be elected in 2012 but it also quickly fired the first ever impeachment in Korea's democratic history. In \"The Networked Public Sphere and Civic Engagement In Post-2011 Egypt\" the author points out that with \"more people and players coming online, online spheres started mirroring the offline ones, rather than informing and influencing them.\" I find this to be an interesting assumption that the emergence of social media would naturally improve the organization of public discourse in physical space. The internet may have democratized the access to information and public discourse, but this alone is not enough for constructive popular organization. Rather, I believe that it is when social media can successfully create empathy among the public thus preventing polarization and opening up echo chambers that can spark exciting, decentralized and truly public decisions.</p>"
 	},
	"week4":
	{
		"week" : "week4",
		"title" : "Modeling Society",
		"subtitle" : "Computability of the real world",
		"date" : "September 25, 2017",
		"text" :"<p>There are two video games that I have ever played of my own free will: Sims and Minecraft. Almost every weekend at the age of 14, I would stay up hours on end personalizing characters, building houses and simulating communities. After awhile the game would get repetitive and predictable, but then I would start over with a new persona, new job, new house and new \"rules to live by.\" </p><p> Why was I so enticed into the game? The pleasure certainly ran deeper than the aesthetic pleasure of creating houses. Perhaps it was the autonomy and control. In his paper \"Dumb People, Smart Objects: The Sims and the Distributed Self\", Jeremy Tirrell explains the intricate architecture of Sims and how it \"identifies a particular model of a distributed self functioning in Sims games that dissolves distinctions between human and object, real and virtual.\" Some aspects of today's reality reflected in the Sims virtuality, such as being interpersonal, restricted in resource and time, and commodity-driven, are obvious and visceral to most players. What is not as manifest, however, is the extent to which a self (both the player's and character's) is defined by objects around it. Tirrell's claim that the distinction between real and virtual, human and object dissolve because Sims adopts and reinforces the philosophy that humans and objects are both equally important and entangled nodes in a network. </p><p> I think Sims is both simplistic and deeply futuristic in representing the real world. The game, although very intricate and meticulous, is still programmed to a set of if else statements, lacking randomness and irrationality that are very present in real life. At the same time, the \"city blocks and transportation systems [that] function as autonomous agents according to rules based upon their physical relationship to other agents\" encapsulates the bottom-up powers of emergence that the recent rise of decentralization and blockchain come to represent. It is fascinating that although human players \"control\" the game flow, they have no means of dictating or governing the Sims reality; no player has a direct control to enforce arbitrary rules or to regulate the interpersonal interactions. This design itself puts humans as a node, rather than a controller, of the decentralized web. </p><p> Can such co-dependent autonomy in which central institutions are just another nodes and not commanding bodies exist in the real world? If inanimate objects without character or irrational decision making dictated humans' behaviors, can we exist without unrest? According to the \"Modeling civil violence: an agent-based computation approach\" paper, two ethnic groups can peacefully co-exist with high legitimacy. If every node perceived each other's right to exist as equal, then cops or legal system are not required to keep peace. If this computational model was realistic enough thus accurate, how can we experiment with a society in which every node is equally legitimate? </p><p> While Tirrell's observation of the reality as a decentralized network between humans and objects is fascinating, I do not see self as something determined by objects. While materialistic ownership is still very dominant, don't we as humans recognize experiences more than physical objects to have shaped our views? Also similar \"local nodes\" share many objects from same computers to public buses, but these alone cannot account for the varying degrees of personality amongst us. </p><p> If I were to play Sims again, would I be as obsessed as I was seven years ago? Probably not. It might be due to the greater autonomy and legitimacy I believe I have in my life. Or could it possibly be the greater freedom I feel from the need to own and abide by the material objects around me?</p>"
	},
	"week3": 
	{
		"week" : "week3",
		"title" : "The Black Box Bias",
		"subtitle" : "Letting the data decide for us",
		"date" : "September 18, 2017",
		"text" : "<p>Machine learning is literally leaving the decision-making process to an algorithm and asking for only the results of a certain computation. This abstraction tool is becoming more accessible as it becomes even more abstracted from the machine into simple libraries like sci-kit learn, with which we can now focus more applying than devising the algorithm. </p><p> One useful application of machine learning is Spotify's Discover Weekly, which trains on individual's weekly music taste and then gives recommendations. The decision-making is relatively simple in this case; we can safely assume that the frequency of listening to a song is highly correlated with our liking for the music, although one week of abnormal listening behavior is likely to very easily throw off the recommendations. It's a relatively simple black box that does what we expect it to that trains on very relevant dataset--individual's playlist. </p><p> Can the same black box be used to identify terrorists to kill? Other machine learning models, however, are hard to predict and ever so data hungry that the priority is often on getting a lot of data regardless of relevance. In the case of calculating a dispersion matrix based on phone signals, contact frequency, geolocation, and other unannotated data, identifying hot nodes thus nominating terrorists to kill is not as simple as predicting someone's music taste. As stated in Weber's paper, it is not easy to foresee terrorist attack based on certain behavior, yet the model assumes certain metrics such as frequency of contact in a social network as a significant indicator of terrorist activity. </p><p> There are numerous levels of abstraction in president's Terror Tuesday decision-making process: first from the unannotated mass data to the machine learning algorithms to software engineers to intelligence agency, then to final decision-making. Isn't it inevitable that a lot of false positives and false negatives will arise along this long and unclear abstraction pipeline? Aren't the consequences of these false signals a matter of life and death? But really, do they care?</p>"
	},
	"week2": 
	{
		"week" : "week2",
		"title" : "Private Persons / Public Space",
		"subtitle" : "Software for and against the public",
		"date" : "September 11, 2017",
		"text" : "<p>Software has fundamentally changed the way both private and public opinions are voiced. Software is not a singular, isolated technology living inside hardware but rather a microcosm of its own, thus inherently ambivalent. The role it has played in voicing individual opinions in the public opinion is especially double-sided.</p><p>The definition of public sphere has changed with every turn in history. As explained in “The Public Sphere: An Encyclopedia Article (1964)” the scope of what public sphere includes has slowly expanded with history. From the feudal times during which the authorities “represent their power before the people, instead of for the people”, the public sphere expanded to include the actual public opinion thanks to the rise of literary journalism. Software has further augmented what journalism achieved in intensifying public discussion. How Twitter gives individuals an equal platform to be heard, sometimes by public officials, is one example of social media as software’s use case is expanding the scope of public sphere. It is not just the end result of using software, but the “actively working with the data: reorganizing it, uncovering the connections, becoming aware of correlations” (Chun, 2004) that software truly becomes a tool of empowerment. I think that one can even argue that writing code is a creative outlet for individuals to communicate.</p><p>Software, however, is also as effective in silencing voices as it is in amplifying them, depending on who is behind building the software. This paradox is like the illusion of transparency that humans see at the cost of hiding the machines. For example, surveillance programs like the Matrix and analytics tools running in between requests and responses is how centralized authorities attempt to influence and breach the public opinion using software. Another example is the polarization of software engineers demographic, especially in gender. Despite many of the first generation programmers being female and machines lacking gender values, software engineering is becoming dominantly male-dominated, just within a few decades of its invention.</p><p>While other industries may also have unbalanced representation, I think an equal representation in race, gender, and other background is especially important in software engineering. Software is referred to as the “actant in the world” that “augments, supplements, mediates, and regulates our live sand opens up new possibilities—but not in a deterministic way” (Kitchen & Dodge, 2011). Software is no longer a product but also a producer in that it disciplines our interactions with and expectations from software. As discussed before, software has a tremendous power of amplifying individual voices. If this gender imbalance persists and software becomes self-fulfilling prophecy that empowers only the voices of its creators-alike, it could become a dangerous loop of restricting the public sphere to only the powerful few, like the past societies.</p>"
	}
}